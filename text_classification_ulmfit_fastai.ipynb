{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on Text Classification (NLP) using ULMFiT and fastai Library in Python\n",
    "links https://www.analyticsvidhya.com/blog/2018/11/tutorial-text-classification-ulmfit-fastai-library/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.text import * \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Import dataset yang ada di sklearn untuk klasifikasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bikin dataframe dan cek shape nya. label sebagai label dari teks, teks itu isi artikelnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'label':dataset.target, 'text':dataset.data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label                                               text\n",
      "0         17  Well i'm not sure about the story nad it did s...\n",
      "1          0  \\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...\n",
      "2         17  Although I realize that principle is not one o...\n",
      "3         11  Notwithstanding all the legitimate fuss about ...\n",
      "4         10  Well, I will have to change the scoring on my ...\n",
      "5         15   \\n \\nI read somewhere, I think in Morton Smit...\n",
      "6          4  \\nOk.  I have a record that shows a IIsi with ...\n",
      "7         17  \\n\\n\\nSounds like wishful guessing.\\n\\n\\n\\n\\n'...\n",
      "8         13   Nobody is saying that you shouldn't be allowe...\n",
      "9         12  \\n  I was wondering if anyone can shed any lig...\n",
      "10         1  Archive-name: graphics/resources-list/part1\\nL...\n",
      "11         6  I have a Roberto Clemente 1969 Topps baseball ...\n",
      "12        13  \\n\\n\"Diet Evangelist\".  Good term.  Fits Atkin...\n",
      "13        15  Hi Damon,  No matter what system or explanatio...\n",
      "14         4  The title says it all.  I need to know the 44,...\n",
      "15        11  \\nCan't we move the political bickering to a m...\n",
      "16        11  Exactly.\\n\\nBut I'll add another observation: ...\n",
      "17        10  \\nAnd of course, Mike Ramsey was (at one time)...\n",
      "18        12  In Texas (Well, Corpus Christi anyway) if you ...\n",
      "19        19  \\n   I'm sorry, I thought we were discussing h...\n",
      "20        12  \\n\\n\\n\\n\\tI'd like to see this info as well.  ...\n",
      "21        12  Just a shot here, but ya never know:\\n\\nI once...\n",
      "22        16  \\nThere is a (likely) veto proof majority in t...\n",
      "23        16  \\n\\n\\n\\n\"Put not your trust in princes\" is the...\n",
      "24        10  As I promised, I would give you the name of th...\n",
      "25        15  The concept of God as a teacher is indeed inte...\n",
      "26         6  \\nIt really doesn't strike me as very funny. I...\n",
      "27        11  \\n\\nI don't know, but I'm as willing to specul...\n",
      "28        10  GAME(S) OF 4/15\\n---------------\\nADIRONDACK 6...\n",
      "29         8  \\nYes!  Up the coast, over to Portland, then u...\n",
      "...      ...                                                ...\n",
      "11284      5                                                ...\n",
      "11285      8                  \\nLike, there's a FAQ for this?\\n\n",
      "11286      7  REQUEST FOR DISCUSSION\\n\\nThis is a request fo...\n",
      "11287     15  Pardon me if this is the wrong newsgroup.  I w...\n",
      "11288      1  Hi there,\\n\\nis there anybody who know a polyg...\n",
      "11289      9  Since someone brought up sports radio, howabou...\n",
      "11290     16   \\n[...]\\n \\n      Well, chalk one up for driv...\n",
      "11291      5  (please respond via email!)\\n\\nHas anybody act...\n",
      "11292      2  Greetings!\\n   \\nI've had a bunch of problems ...\n",
      "11293      2  \\n@===@                                       ...\n",
      "11294     12  I had a catalog with membrane keypads, but I d...\n",
      "11295      8  Oh boy, a little K-bike versus /2 scuffling? G...\n",
      "11296     13  Hello to everybody,\\nI write here because I am...\n",
      "11297     13  [reply to todamhyp@charles.unlv.edu (Brian M. ...\n",
      "11298     16  This is exactly what I have heard before.  If ...\n",
      "11299     11  \\nWhats the difference between a V.32bis modem...\n",
      "11300      0  [why do babies get diseases, etc.]\\n\\n Here's ...\n",
      "11301      4  I would like to know what people's opinions ar...\n",
      "11302     10  You might want to clarify the 11 game winning ...\n",
      "11303     15  \\nI totally agree with that sentiment.  But wh...\n",
      "11304     15  \\nI agree with what Darren has to say here, bu...\n",
      "11305      6  Ok people, I really need to sell this sampler ...\n",
      "11306      5  Hi,\\n\\n  I am trying to write an X-windows bas...\n",
      "11307     15  I'd like to share my thoughts on this topic of...\n",
      "11308      7  My sunroof leaks.  I've always thought those t...\n",
      "11309     17  Danny Rubenstein, an Israeli journalist, will ...\n",
      "11310     13                                                 \\n\n",
      "11311      9  \\nI agree.  Home runs off Clemens are always m...\n",
      "11312      4  I used HP DeskJet with Orange Micros Grappler ...\n",
      "11313      9                                        ^^^^^^\\n...\n",
      "\n",
      "[11314 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "supaya bisa jadi binary classification, cuma pilih 2 label, yaitu 1 dan 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['label'].isin([1,10])]\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    600\n",
       "1     584\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. buat teks nya, cuma select huruf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace(\"[^a-zA-Z]\", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. download stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. tokenization, remove stop-words, de-tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization \n",
    "tokenized_doc = df['text'].apply(lambda x: x.split())\n",
    "\n",
    "# remove stop-words \n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "# de-tokenization \n",
    "detokenized_doc = [] \n",
    "for i in range(len(df)): \n",
    "    t = ' '.join(tokenized_doc[i]) \n",
    "    detokenized_doc.append(t) \n",
    "\n",
    "df['text'] = detokenized_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and validation set\n",
    "df_trn, df_val = train_test_split(df, stratify = df['label'], test_size = 0.4, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cek shape nya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((710, 2), (474, 2))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label                                               text\n",
      "1018     10  It looks like Edmonton Oilers decided take Eur...\n",
      "762      10  This kills Speaking die hard I I read died har...\n",
      "768       1  The idea clip one polygon using another polygo...\n",
      "152      10  I Edmonton usually least OFTEN case treated ac...\n",
      "426      10  You know absolutely right I think round player...\n",
      "489      10  Did boyfriend comment fact Clement looks like ...\n",
      "533      10  Ten years ago number Europeans NHL roughly qua...\n",
      "731       1  I went back looked review They claim significa...\n",
      "890       1  I need information Display PostScript strokead...\n",
      "588      10  I disagree one I think Vancouver go Bure goes ...\n",
      "1074     10  Wales Conference Adams Division Semifinal I ho...\n",
      "448      10  Last night Sharks broadcast Commissioner Bettm...\n",
      "1060     10    Do realize many smiles crossing faces wrote gld\n",
      "824       1  I got spec obviously since I quoted last posti...\n",
      "1112      1  HELP MY FRIEND AND I HAVE A CLASS PROJECT IN W...\n",
      "350      10  Yes shame NHL lost fine team one best hockey m...\n",
      "779      10  After watching Pengiuns year many teams possib...\n",
      "172       1                                                   \n",
      "776       1  I looking leads source good Windows Meta File ...\n",
      "1166      1  Are TIFF anything programs IBM Our scanner wor...\n",
      "286      10  Ooops read Selke forgive insolence congenially...\n",
      "300       1  Sketch Rotate cylinder axis Z axis Intersect X...\n",
      "463      10  OK I join fun give playoff predictions st roun...\n",
      "478      10  Here traditional experience tickets playoffs o...\n",
      "486      10  IMO good player score power plays man advantag...\n",
      "275       1  They D object files CAD D program written Tom ...\n",
      "251       1  I following thread appologies already mentione...\n",
      "599       1  Hi I searching packages could handle Multi pag...\n",
      "178       1  Look edge inconsistencies Consider two vertice...\n",
      "76       10  In qvos r cl msu vergolin euler lbs msu edu Da...\n",
      "...     ...                                                ...\n",
      "169      10  Wrong information They announced Suhonen made ...\n",
      "1071      1  Looking graphics CAD whatever package X Unix b...\n",
      "703       1  Hi anyone info XGA chipset HW funcs TrueColor ...\n",
      "517      10  Yup I agree ya I think Devils beat Red Wings e...\n",
      "902       1  I looking copy following Siggraph publication ...\n",
      "625       1  Does anybody know Delaunay Triangulation Is re...\n",
      "465       1  Update location Directory public virtual world...\n",
      "906      10  Messier Samuelsson incident I agree Rick Ulf c...\n",
      "881       1  We minivas want record Abekas A We functions w...\n",
      "456      10  Just quick note Manon immediate future Rumor U...\n",
      "736      10  Kevin Todd Oiler one months How closely follow...\n",
      "602      10  Interesting One German friends Robert told for...\n",
      "717      10  Here press release White House Remarks Preside...\n",
      "900      10  According hockey gurus ESPN Islanders win toni...\n",
      "539       1  Hi Steve As author Multiverse I feel I better ...\n",
      "828      10  Ok seen Tabaracci play yet In two starts relie...\n",
      "89        1  Hello I trying bump map gif onto sphere I seem...\n",
      "436       1         Try graPHIGS IBM It excellent package Doug\n",
      "583       1  I good fortune hired Electronic Arts Senior Co...\n",
      "278       1  I sure use version It works fine software NOT ...\n",
      "991       1  I sure I amused Every time I read part TIFF sp...\n",
      "1008      1  Is FTP archive United States Geological Servic...\n",
      "409      10  I loved Dan Kelly He USA I first got hooked Ho...\n",
      "382      10  Here summary Don Cherry coach corner April It ...\n",
      "532       1  I happy US international Snail mail technical ...\n",
      "833       1                           Forty two six times nine\n",
      "378      10  Re Eric True fortunately get find would like w...\n",
      "791      10  Well tentative rules anyway And course since s...\n",
      "200      10  The FLYERS closed season last night th straigh...\n",
      "801       1  Actually I trying write something like I encou...\n",
      "\n",
      "[710 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Siapkan language model sama classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "```text\n",
      "=== Software === \n",
      "python version : 3.6.4\n",
      "fastai version : 1.0.34\n",
      "torch version  : 1.0.0\n",
      "torch cuda ver \n",
      "torch cuda is  : **Not available** \n",
      "\n",
      "=== Hardware === \n",
      "No GPUs available \n",
      "\n",
      "=== Environment === \n",
      "platform       : Windows-10-10.0.17134-SP0\n",
      "conda env      : Unknown\n",
      "python         : C:\\Users\\RandomScientist\\Anaconda3\\python.exe\n",
      "sys.path       : \n",
      "C:\\Users\\RandomScientist\\Anaconda3\\python36.zip\n",
      "C:\\Users\\RandomScientist\\Anaconda3\\DLLs\n",
      "C:\\Users\\RandomScientist\\Anaconda3\\lib\n",
      "C:\\Users\\RandomScientist\\Anaconda3\n",
      "C:\\Users\\RandomScientist\\Anaconda3\\lib\\site-packages\n",
      "C:\\Users\\RandomScientist\\Anaconda3\\lib\\site-packages\\win32\n",
      "C:\\Users\\RandomScientist\\Anaconda3\\lib\\site-packages\\win32\\lib\n",
      "C:\\Users\\RandomScientist\\Anaconda3\\lib\\site-packages\\Pythonwin\n",
      "C:\\Users\\RandomScientist\\Anaconda3\\lib\\site-packages\\IPython\\extensions\n",
      "C:\\Users\\RandomScientist\\.ipython\n",
      "no supported gpus found on this system\n",
      "```\n",
      "\n",
      "Please make sure to include opening/closing ``` when you paste into forums/github to make the reports appear formatted as code sections.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# preview of my system\n",
    "from fastai.utils import show_install\n",
    "show_install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-2e87b7216454>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Language model data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata_lm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextLMDataBunch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_trn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fastai\\text\\data.py\u001b[0m in \u001b[0;36mfrom_df\u001b[1;34m(cls, path, train_df, valid_df, test_df, tokenizer, vocab, classes, text_cols, label_cols, label_delim, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m         src = ItemLists(path, TextList.from_df(train_df, path, cols=text_cols, processor=processor),\n\u001b[0;32m    169\u001b[0m                         TextList.from_df(valid_df, path, cols=text_cols, processor=processor))\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_for_lm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mTextLMDataBunch\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_from_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel_delim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTextList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatabunch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fastai\\data_block.py\u001b[0m in \u001b[0;36m_inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    373\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelLists\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_inner\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fastai\\data_block.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;34m\"Process the inner datasets.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m         \u001b[0mxp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_processors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mds\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter_missing_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fastai\\data_block.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, xp, yp, filter_missing_y)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[0mfilt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfilt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mfilt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mfilt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fastai\\data_block.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, processor)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlistify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fastai\\text\\data.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, ds)\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m             \u001b[0mtokens\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m         \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fastai\\text\\transform.py\u001b[0m in \u001b[0;36mprocess_all\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_cpus\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_all_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mProcessPoolExecutor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_cpus\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_all_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartition_by_cores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_cpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mVocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\process.py\u001b[0m in \u001b[0;36m_chain_from_iterable_of_lists\u001b[1;34m(iterable)\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[0mcareful\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mto\u001b[0m \u001b[0mkeep\u001b[0m \u001b[0mreferences\u001b[0m \u001b[0mto\u001b[0m \u001b[0myielded\u001b[0m \u001b[0mobjects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \"\"\"\n\u001b[1;32m--> 366\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m         \u001b[0melement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    584\u001b[0m                     \u001b[1;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                         \u001b[1;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "# Language model data\n",
    "data_lm = TextLMDataBunch.from_df(path=\"\", train_df = df_trn, valid_df = df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_lm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-892cd3040c30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Classifier model data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata_clas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextClasDataBunch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_trn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_lm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data_lm' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Classifier model data\n",
    "data_clas = TextClasDataBunch.from_df(path = \"\", train_df = df_trn, valid_df = df_val, vocab=data_lm.train_ds.vocab, bs=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, pretrained_model=URLs.WT103, drop_mult=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the learner object with learning rate = 1e-2\n",
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save encoder buat classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('ft_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pakai data_clas untuk fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_clas, drop_mult=0.7)\n",
    "learn.load_encoder('ft_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "preds, targets = learn.get_preds()\n",
    "\n",
    "predictions = np.argmax(preds, axis = 1)\n",
    "pd.crosstab(predictions, targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
